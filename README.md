# Data-Science-and-Big-Data-Analytics
Lab Practical Group A: Data Science 

# Introduction
This repository contains lab practicals for the Data Science and Big Data Analytics . The practicals cover a wide range of topics, including data wrangling, descriptive statistics, data analytics, text analytics, and data visualization. Each practical includes detailed instructions, code, and explanations.


# Usage
You can run the notebooks or scripts in this repository using Google Colab, an online platform for running Jupyter notebooks, or any local Python environment such as Jupyter Notebook or PyCharm.
1. Google Colab:
   1. Open the notebook you want to run.
   2. Click on the "Open in Colab" badge at the top of the notebook to open it in Google Colab.
   3. Execute the cells in the notebook by clicking the play button next to each cell.

2. Local Python Environment:
   1. If you prefer running the notebooks locally, you can use Jupyter Notebook or any IDE such as PyCharm.
   2. Download the notebook files from the repository.
   3. Open the notebook in your preferred environment.
   4. Execute the cells in the notebook to run the code.
      
# Lab Practicals
Group A: Data Science
# 1. Data Wrangling I
Objective: Perform data wrangling operations on an open source dataset.
Steps:
  1. Import all the required Python libraries.
  2. Locate and describe an open source dataset.
  3. Load the dataset into a pandas dataframe.
  4. Data preprocessing: check for missing values, describe the data, and provide variable descriptions.
  5. Data formatting and normalization: summarize types of variables and apply type conversions if necessary.
  6. Convert categorical variables into quantitative variables.

# 2. Data Wrangling II
Objective: Create an academic performance dataset and perform data wrangling operations.
Steps:
  1. Scan for missing values and inconsistencies.
  2. Scan for outliers in numeric variables and handle them.
  3. Apply data transformations on at least one variable for better understanding or normalization.

# 3. Descriptive Statistics
Objective: Perform descriptive statistics on an open source dataset.
Steps:
  1. Provide summary statistics for numeric variables grouped by a categorical variable.
  2. .Display basic statistical details like percentiles, mean, and standard deviation.

# 4. Data Analytics I
Objective: Create a linear regression model to predict home prices using the Boston Housing dataset.

# 5. Data Analytics II
Objective: Implement logistic regression for classification on the Social_Network_Ads dataset.
Steps:
  1. Implement logistic regression.
  2. Compute confusion matrix and various performance metrics.

# 6. Data Analytics III
Objective: Implement Naïve Bayes classification on the Iris dataset.
Steps:
  1. Implement the Naïve Bayes algorithm.
  2. Compute confusion matrix and various performance metrics.

# 7. Text Analytics
Objective: Perform text preprocessing and document representation.
Steps:
  1. Apply tokenization, POS tagging, stop words removal, stemming, and lemmatization.
  2. Calculate term frequency and inverse document frequency.

# 8. Data Visualization I
Objective: Visualize the Titanic dataset using Seaborn.
Steps:
  1. Identify patterns in the Titanic dataset.
  2. Plot a graphs.
   
# 9. Data Visualization II
Objective: Create a box plot for age distribution by gender and survival status using the Titanic dataset.
Steps:
  1. Plot the box plot.
  2. Write observations based on the box plot.

# 10. Data Visualization III
Objective: Analyze the Iris dataset.
Steps:
  1. List features and their types.
  2. Create histograms and box plots for each feature.
  3. Compare distributions and identify outliers.

# Contact
For any questions , please contact me at [peter.rizza.15@gmail.com].
